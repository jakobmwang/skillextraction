{"cells":[{"cell_type":"markdown","metadata":{"id":"X8VR8TxNxqk7"},"source":["# Installation and Importing"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GJnIx8Q8xY6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734524121824,"user_tz":-60,"elapsed":13870,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"outputId":"eae63e51-64fa-441a-d94a-43aebeb89cee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# dependencies\n","import os\n","import gc\n","import time\n","import random\n","import csv\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau\n","from torch.nn.utils import clip_grad_norm_\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","from datetime import datetime\n","from transformers import AutoModel, AutoTokenizer\n","from google.colab import drive, userdata\n","\n","# file management\n","drive.mount('/content/drive')\n","WORK_DIR = '/content/drive/MyDrive/Projects/skillextraction'\n","\n","# work dir shortcut function\n","def work_dir(*args):\n","    return os.path.join(WORK_DIR, *args)"]},{"cell_type":"markdown","metadata":{"id":"QFTkVCN_oudy"},"source":["# Configuration"]},{"cell_type":"code","source":["# config container\n","class C:\n","\n","    # architecture\n","    BASE_MODEL = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n","    PROXY_GROUPS = [1] # label_en = [1], label_da = [2], desc_en = [3], desc_da = [4]\n","    SAMPLE_GROUPS = [5] # original synthetic = [5], translated = [6]\n","    AVERAGE_EMBEDDINGS = False\n","    SEQ_LENGTH = 256 # 99.9th percentile of bench, 100% of others\n","    IS_SKILL_DIM = 8 # how many dimensions are read out for is_skill\n","    ATP_TEMPERATURE = 0.05\n","\n","    # training\n","    N_LAYERS = 5\n","    LR = 1e-6\n","    LR_INITIAL = 1e-8\n","    LR_LAYER_FACTOR = 0.5\n","    LR_REDUCE_FACTOR = 0.1\n","    LR_WARMUP_FACTOR = 1.0005\n","    TRAIN_METHOD = 'direct' # 'direct', 'mnr'\n","    BATCH_SIZE = 32\n","    EPOCHS = 0\n","    PATIENCE = 3 # early stopping\n","    SKILL_ID_TEMP = 0.05\n","    SKILL_ID_TEMP_INITIAL = 1.0\n","    SKILL_ID_TEMP_FACTOR = 0.9999\n","    IS_SKILL_FP_PENALTY = 1.005 # false positives loss multipler\n","    BEST_METRIC = 'val_skill_id_loss'\n","    BEST_METRIC_OPT = 'min'\n","\n","    # regularization\n","    DROPOUT_RATE = 0.1\n","    WEIGHT_DECAY_RATE = 0.1\n","\n","    # system\n","    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    NUM_WORKERS = 2\n","    PREFETCH_FACTOR = 1\n","\n","    # export path\n","    def PATH(postfix=''):\n","        return work_dir('experiments', '-'.join(str(v).replace('/', '-') for k, v in vars(C).items() if k.isupper() and k != 'PATH') + postfix)\n","\n","# check config-aggregated path\n","C.PATH('.csv')"],"metadata":{"id":"imF1lwZErTY8","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1734524121825,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"outputId":"9a89bd1e-ab20-4d88-e01d-1a1425340220"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Projects/skillextraction/experiments/sentence-transformers-paraphrase-multilingual-mpnet-base-v2-[1]-[5]-False-256-8-0.05-5-1e-06-1e-08-0.5-0.1-1.0005-direct-32-0-3-0.05-1.0-0.9999-1.005-val_skill_id_loss-min-0.1-0.1-cuda-2-1.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"r531y35IvrYe"},"source":["# Dataframes"]},{"cell_type":"code","source":["# load pre-organized data\n","skills = pd.read_json(work_dir('Data', 'skills.json'), orient='records', lines=True)\n","nonskills = pd.read_json(work_dir('Data', 'nonskills.json'), orient='records', lines=True)\n","bench = pd.read_json(work_dir('Data', 'bench.json'), orient='records', lines=True)\n","\n","# assign id's to conceptUri's\n","uri_ids = skills['conceptUri'].unique()\n","uri_ids = dict(zip(uri_ids, range(len(uri_ids))))\n","\n","# map id's for skills and bench\n","skills['id'] = skills['conceptUri'].map(uri_ids)\n","bench['id'] = bench['conceptUri'].map(uri_ids)\n","\n","# padding id for nonskills\n","nonskills['id'] = -1\n","\n","# extract skills from bench for validation and test\n","validation = bench[bench['group'].isin([1, 3, 6, 8])].reset_index(drop=True)\n","test = bench[bench['group'].isin([2, 4, 5, 7, 9, 10])].reset_index(drop=True)\n","\n","# extract and append nonskills for validation from manually annotated\n","val_nonskills = nonskills[nonskills['group'].isin([2, 3])].sample(len(validation), random_state=7)\n","nonskills.drop(val_nonskills.index, inplace=True)\n","validation = pd.concat([validation, val_nonskills], ignore_index=True).reset_index(drop=True)\n","\n","# extract and append nonskills for test from manually annotated\n","test_nonskills = nonskills[nonskills['group'].isin([2, 3])].sample(len(test), random_state=7)\n","nonskills.drop(test_nonskills.index, inplace=True)\n","test = pd.concat([test, test_nonskills], ignore_index=True).reset_index(drop=True)\n","\n","# check\n","print(skills.shape, nonskills.shape, validation.shape, test.shape)\n","skills.columns, nonskills.columns, validation.columns, test.columns"],"metadata":{"id":"gzG5DbdL15Nr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734524132319,"user_tz":-60,"elapsed":10500,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"outputId":"246a4227-7475-424c-b9e8-09e4a5d82bc2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(331512, 4) (95818, 3) (1110, 4) (7254, 4)\n"]},{"output_type":"execute_result","data":{"text/plain":["(Index(['conceptUri', 'sentence', 'group', 'id'], dtype='object'),\n"," Index(['group', 'sentence', 'id'], dtype='object'),\n"," Index(['conceptUri', 'group', 'sentence', 'id'], dtype='object'),\n"," Index(['conceptUri', 'group', 'sentence', 'id'], dtype='object'))"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# Tokenizer"],"metadata":{"id":"7MiPSKFqTnjv"}},{"cell_type":"code","source":["# initialize tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(C.BASE_MODEL)"],"metadata":{"id":"lot_XPiPTo0l","executionInfo":{"status":"ok","timestamp":1734524146449,"user_tz":-60,"elapsed":14134,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["008d806633d849cfbbd1b6f54021794e","80ee07afcfcc4e659a0b9e7abef3bee0","a398249b641e4c14b387c4777b2b4aa8","9e562410dd7547f58eee8afac2cc9c9b","6f1381ba18a14162aceeb927f69d7842","7d19f08b590e45b38387acd902ec126c","478e703c6f2748f6bb472c649c75ed3c","34928e1edf7a47409386e932b3286898","ab919e8699dc4694bee0775b86a56422","cb42de71b2cf4d1eb81cdb13bf9cf64e","c621449554fe486abb17f5ec21268d30","c1f135e9eddd41e297cb29efc050e339","cb2bd583958342f48ca700e07050edbb","5fd145e907dd4441a661871c9db47c8b","bf02100e17644d05a0c0d00753cfb1b1","5e1bf183e85f41979d4829f451997bf3","c64533298c124910a4340704ba61df33","e430ce3ad0514ac6ac9b5dc497ae6f58","287260ec7ee24aa19afd25eb999e110e","9975db8e08b3433faa0fd0cae982e5df","7a81259cf21240638d99dbe73c3bc35d","55dac3e1755c438eade0ca392eb6387f","21b3ca01d81c495392cebeb33326d347","32e592dca9dd4852be3051d6dd09ba64","1cd7a55470024a46a49d35b4864f5369","5dfbecf2b3814ac08ea334b21526cf05","3747ec1233ca4642899fb09bbdd6400c","d9757a8359ba4f6fb3650df806129b34","8e97b11d86c64da18fd6499c6c47cce6","47cb0d14a1e04b81a06a460f59e35910","1cbc5b1f4a2048318101b02f2e0bd489","87a80bd688814f2d97363192bd7def6e","c391cdc01b8e42f4aa97f1ee6e193c11","eef839ad3f6944f2a2ae1ba96e0eb060","5226830a4d7e4fbe8d4c39e8ffdf5e57","3a042f2bd84546b687812e0de5bca354","d95a69a4d4944a9d944449bb9dd0b667","cd3ebf24070b427da6cdaadbb851ad61","20071098e1e24e5a83d28bef2725d0c5","a862c53bd7264760ad4128766070f4cc","eb4d531a41a34fc69e168897bac1107a","908e5f5f11ff406a81e4641f5ccbd253","9e971f36a0fb4b43862c0e00e84b7db8","f1b04dceb8a044e9a5fd7c9ea9055e35","c10ccc2c481045d4adb6a36e9e3b0c9a","a81363afe1c741308b275a6a8609121b","5c2044799e8943e6981ed72fae90505d","1d41ecebb92442ba8a5362835dd5e22d","5ecb00828e9445559f6702605534c70d","c6d4e8e71e944a22b3cbfed1d96e5694","3061e0e9204a49c48188e1a444fe8755","b3d8e556f0a944ddb6ccbd5665526d62","e3e028d402b6411fb04fc80ad82dba19","52c7145abac04674b7394bc0ed6e1eae","8992cb7bd4ba4f43a05369a0b414f045"]},"outputId":"2c55f638-193c-4360-a6fe-fc1baa300891"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008d806633d849cfbbd1b6f54021794e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1f135e9eddd41e297cb29efc050e339"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b3ca01d81c495392cebeb33326d347"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eef839ad3f6944f2a2ae1ba96e0eb060"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c10ccc2c481045d4adb6a36e9e3b0c9a"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"g3w4fpmMc0Su"},"source":["# Datasets"]},{"cell_type":"code","source":["# define multi purpose dataset, e.g. proxies for predictor, samples for training, bench for evaluating\n","class SkillData(Dataset):\n","\n","    # init that handles different usages, calculates length based on usage (num unique id for proxies)\n","    def __init__(self, tokenizer, proxies=None, samples=None, nonskills=None, seq_length=256):\n","        super().__init__()\n","        self.tokenizer = tokenizer\n","        self.proxies = proxies\n","        self.samples = samples\n","        self.nonskills = nonskills\n","        self.seq_length = seq_length\n","        # calculate number of proxies per skill and number of samples (unique for proxies, all for others)\n","        self.n_proxies = self.proxies['id'].value_counts().min() if proxies is not None else 0\n","        self.n = self.proxies['id'].nunique() if proxies is not None and samples is None else len(self.samples)\n","\n","    def __len__(self):\n","        return self.n\n","\n","    def __getitem__(self, i):\n","        return i\n","\n","    # shortcut tokenize\n","    def tokenize(self, sentences, max_length=True):\n","        return tokenizer(sentences,\n","                         padding='max_length' if max_length else 'longest',\n","                         truncation=True,\n","                         max_length=self.seq_length if max_length else None,\n","                         return_tensors='pt')\n","\n","    # augment into pairs of sentences, even / odd\n","    def augment(self, samples):\n","        s1 = samples['sentence'].iloc[::2].reset_index(drop=True)\n","        s2 = samples['sentence'].iloc[1::2].reset_index(drop=True)\n","        s3 = pd.Series()\n","        if len(s1) > len(s2):\n","            s3 = s1.iloc[-1:]\n","            s1 = s1.iloc[:-1]\n","        return samples.reset_index(drop=True).assign(\n","            sentence=pd.concat([np.repeat(s1 + ' ' + s2, 2), s3], ignore_index=True).reset_index(drop=True)\n","        )\n","\n","    # collate proxy loading\n","    def proxy_collate(self, ids):\n","        proxies = self.proxies.loc[self.proxies['id'].isin(ids)].groupby('id').head(self.n_proxies)\n","        tokens = self.tokenize(proxies['sentence'].tolist())\n","        return {'id': torch.tensor(proxies['id'].tolist(), dtype=torch.long),\n","                'input_ids': tokens['input_ids'],\n","                'attention_mask': tokens['attention_mask']}\n","\n","    # collate direct training\n","    def train_collate(self, idx):\n","        samples = self.samples.loc[self.samples.index.isin(idx)]\n","        samples = self.augment(samples)\n","        samples = pd.concat([samples, self.nonskills.sample(len(samples), random_state=7)], ignore_index=True)\n","        tokens = self.tokenize(samples['sentence'].tolist(), max_length=False)\n","        group = ((samples['id'] > -1) * samples['group']).tolist()\n","        sentence_ids = dict(zip(samples['sentence'].unique(), range(len(samples['sentence'].unique()))))\n","        sentence = samples['sentence'].map(sentence_ids)\n","        return {'id': torch.tensor(samples['id'].tolist(), dtype=torch.long),\n","                'input_ids': tokens['input_ids'],\n","                'attention_mask': tokens['attention_mask'],\n","                'group': torch.tensor(group, dtype=torch.long),\n","                'sentence': torch.tensor(sentence.tolist(), dtype=torch.long)}\n","\n","    # collate evaluation\n","    def eval_collate(self, idx):\n","        samples = self.samples.loc[self.samples.index.isin(idx)]\n","        tokens = self.tokenize(samples['sentence'].tolist())\n","        group = ((samples['id'] > -1) * samples['group']).tolist()\n","        sentence_ids = dict(zip(self.samples['sentence'].unique(), range(len(self.samples['sentence'].unique()))))\n","        sentence = samples['sentence'].map(sentence_ids)\n","        return {'id': torch.tensor(samples['id'].tolist(), dtype=torch.long),\n","                'input_ids': tokens['input_ids'],\n","                'attention_mask': tokens['attention_mask'],\n","                'group': torch.tensor(group, dtype=torch.long),\n","                'sentence': torch.tensor(sentence.tolist(), dtype=torch.long)}\n","\n","# initialize datasets\n","\n","proxy_data = SkillData(tokenizer=tokenizer,\n","                       proxies=skills.loc[skills['group'].isin(C.PROXY_GROUPS)],\n","                       seq_length=C.SEQ_LENGTH)\n","\n","train_data = SkillData(tokenizer=tokenizer,\n","                       samples=skills.loc[skills['group'].isin(C.SAMPLE_GROUPS)],\n","                       nonskills=nonskills,\n","                       seq_length=C.SEQ_LENGTH)\n","\n","val_data = SkillData(tokenizer=tokenizer,\n","                     samples=validation,\n","                     seq_length=C.SEQ_LENGTH)\n","\n","test_data = SkillData(tokenizer=tokenizer,\n","                      samples=test,\n","                      seq_length=C.SEQ_LENGTH)\n","\n","# initialize dataloaders\n","\n","proxy_loader = DataLoader(proxy_data,\n","                          batch_size=C.BATCH_SIZE,\n","                          num_workers=C.NUM_WORKERS,\n","                          prefetch_factor=C.PREFETCH_FACTOR,\n","                          collate_fn=proxy_data.proxy_collate,\n","                          shuffle=False,\n","                          pin_memory=True,\n","                          persistent_workers=True)\n","\n","train_loader = DataLoader(train_data,\n","                          batch_size=C.BATCH_SIZE,\n","                          num_workers=C.NUM_WORKERS,\n","                          prefetch_factor=C.PREFETCH_FACTOR,\n","                          collate_fn=train_data.train_collate,\n","                          shuffle=True,\n","                          pin_memory=True,\n","                          persistent_workers=True)\n","\n","val_loader = DataLoader(val_data,\n","                        batch_size=C.BATCH_SIZE,\n","                        num_workers=C.NUM_WORKERS,\n","                        prefetch_factor=C.PREFETCH_FACTOR,\n","                        collate_fn=val_data.eval_collate,\n","                        shuffle=False,\n","                        pin_memory=True,\n","                        persistent_workers=True)\n","\n","test_loader = DataLoader(test_data,\n","                         batch_size=C.BATCH_SIZE,\n","                         num_workers=C.NUM_WORKERS,\n","                         prefetch_factor=C.PREFETCH_FACTOR,\n","                         collate_fn=test_data.eval_collate,\n","                         shuffle=False,\n","                         pin_memory=True,\n","                         persistent_workers=True)\n","\n","# check\n","proxy_data.n, train_data.n, val_data.n, test_data.n"],"metadata":{"id":"X8MjiIDeMr4W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734524146449,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"outputId":"97b54cff-0c46-4755-c7e9-6857786b2e03"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13813, 138130, 1110, 7254)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"ZMOXbk_jnHXW"},"source":["# Base Model"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"keVgpZLUFArQ","executionInfo":{"status":"ok","timestamp":1734524160796,"user_tz":-60,"elapsed":14349,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["dcbcc1f8c4df4d8a9500b0d6fe1814e1","757008cb86264879922ac9c1690a022e","9b6e6231f8684faa9312d63962888bf4","feb29695d66f414684560afdf5bf1011","d56edda780e24d97811fbf7de945d8c4","40517a1596b243b3814cd2f072f4d70e","b85f08d974794e62a7c19a0208f92140","bb499453ac174614a6f8daf1e83e548c","917e84db6908496e84d21a40613a4338","507847201ec2413eb36d7f34aaaaae23","67403d7589984e9780938eacfb276f22"]},"outputId":"6153ba6d-53ac-4be4-d744-7c7db3ccdd00"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcbcc1f8c4df4d8a9500b0d6fe1814e1"}},"metadata":{}}],"source":["# initialize base model\n","base_model = AutoModel.from_pretrained(C.BASE_MODEL).to(C.DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"6c69TNhUFBhC"},"source":["# Embedder"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pNw_MhAV9nP_","executionInfo":{"status":"ok","timestamp":1734524160796,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}}},"outputs":[],"source":["# define embedder\n","class SkillEmbedder(nn.Module):\n","\n","    # initialize with base model and dropout rate\n","    def __init__(self, base_model, dropout_rate):\n","        super().__init__()\n","        self.base_model = base_model\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","    # embed using batch input_ids and attention_mask (including attention mean pooling!)\n","    def forward(self, input_ids, attention_mask):\n","        embeddings = self.base_model(input_ids, attention_mask).last_hidden_state#.mean(dim=1)\n","        embeddings = (embeddings * attention_mask.unsqueeze(-1)).sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n","        return self.dropout(embeddings)\n","\n","# init embedder\n","embedder = SkillEmbedder(base_model=base_model, dropout_rate=C.DROPOUT_RATE).to(C.DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"Hb8HZaFAQga4"},"source":["# Predictor"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"SeeKhq2gQht3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734524171210,"user_tz":-60,"elapsed":10418,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"outputId":"311b5474-8662-4848-ec24-b971958b96ee"},"outputs":[{"output_type":"stream","name":"stderr","text":["Updating proxy embeddings: 100%|██████████| 432/432 [00:10<00:00, 40.98batch/s]\n"]}],"source":["# define predictor\n","class SkillPredictor(nn.Module):\n","\n","    # initialize embedder, proxy_loader and proxy embeddings\n","    def __init__(self, embedder, proxy_loader, average, is_skill_dim):\n","\n","        super().__init__()\n","\n","        self.embedder = embedder\n","        self.proxy_loader = proxy_loader\n","        self.average = average\n","        self.is_skill_dim = is_skill_dim\n","        self.embeddings = nn.Parameter(torch.zeros(self.proxy_loader.dataset.n,\n","                                                  1 if self.average else self.proxy_loader.dataset.n_proxies,\n","                                                  self.embedder.base_model.config.hidden_size,\n","                                                  dtype=torch.half),\n","                                       requires_grad=False)\n","\n","    # update proxy embeddings\n","    def update_embeddings(self):\n","\n","        training = embedder.training\n","        embedder.eval()\n","        pbar = tqdm(proxy_loader, desc=f'Updating proxy embeddings', unit='batch')\n","\n","        with torch.no_grad():\n","            for batch in pbar:\n","                with torch.amp.autocast(str(self.embeddings.device)):\n","                    batch = {k: v.to(self.embeddings.device) for k, v in batch.items()}\n","                    embeddings = embedder(batch['input_ids'], batch['attention_mask']).to(torch.half)\n","                    for id in batch['id'].unique():\n","                        skill_embeddings = embeddings[batch['id'] == id]\n","                        self.embeddings[id] = skill_embeddings.mean(dim=0, keepdim=True) if self.average else skill_embeddings\n","\n","        embedder.train(training)\n","\n","    # predict is_skill from n'th dimension(s) and skill_id from proxy embedding similarity\n","    def forward(self, embeddings, include='both', logits=False):\n","\n","        if include in ('both', 'all', 'is_skill'):\n","            is_skill = embeddings[:, -self.is_skill_dim:].mean(dim=-1)\n","            is_skill = is_skill if logits else F.sigmoid(is_skill)\n","            if include == 'is_skill':\n","                return is_skill\n","\n","        if include in ('both', 'all', 'skill_id'):\n","            sims = F.cosine_similarity(embeddings.unsqueeze(1).unsqueeze(1),\n","                                       self.embeddings,\n","                                       dim=-1).max(dim=-1)[0]\n","            skill_id = sims if logits else F.softmax(sims, dim=-1)\n","            if include == 'skill_id':\n","                return skill_id\n","\n","        return is_skill, skill_id\n","\n","# init predictor\n","predictor = SkillPredictor(embedder=embedder, proxy_loader=proxy_loader, average=C.AVERAGE_EMBEDDINGS, is_skill_dim=C.IS_SKILL_DIM).to(C.DEVICE)\n","predictor.update_embeddings()"]},{"cell_type":"markdown","source":["# Criterion"],"metadata":{"id":"K2utPywi9C2M"}},{"cell_type":"code","source":["# define criterion\n","class SkillCriterion(nn.Module):\n","    def __init__(self, is_skill_fp_penalty=0.0, skill_id_temperature=1.0):\n","        super().__init__()\n","        self.is_skill_fp_penalty = is_skill_fp_penalty\n","        self.skill_id_temperature = skill_id_temperature\n","\n","    # calculate loss for is_skill (with false positives penalty) and skill_id (with temperature)\n","    def forward(self, is_skill_logits, is_skill_labels, skill_id_logits, skill_id_labels):\n","        is_skill_loss = F.binary_cross_entropy_with_logits(is_skill_logits.float(),\n","                                                           is_skill_labels.float(),\n","                                                           reduction='none')\n","        is_skill_loss *= ((is_skill_logits > 0.0) & (~is_skill_labels.bool())).long() * self.is_skill_fp_penalty\n","        is_skill_loss = is_skill_loss.mean()\n","        if (skill_id_labels > -1).sum() > 0:\n","            skill_id_loss = F.cross_entropy(skill_id_logits / self.skill_id_temperature, skill_id_labels, ignore_index=-1)\n","        else:\n","            skill_id_loss = torch.tensor(0.0, device=is_skill_logits.device)\n","        return is_skill_loss + skill_id_loss, {'is_skill_loss': is_skill_loss.item(), 'skill_id_loss': skill_id_loss.item()}\n","\n","# init criterion\n","criterion = SkillCriterion(is_skill_fp_penalty=C.IS_SKILL_FP_PENALTY, skill_id_temperature=C.SKILL_ID_TEMP_INITIAL).to(C.DEVICE)"],"metadata":{"id":"kLvh55L89Ey8","executionInfo":{"status":"ok","timestamp":1734524171210,"user_tz":-60,"elapsed":9,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Metrics"],"metadata":{"id":"FxdwSjrZ5sr6"}},{"cell_type":"code","source":["# define metrics (needs vectorizing)\n","class SkillMetrics(nn.Module):\n","    def __init__(self, atp_temperature=1.0):\n","        super().__init__()\n","        self.atp_temperature = atp_temperature\n","\n","    # calculate metrics\n","    def forward(self, is_skill_logits, is_skill_labels, skill_id_logits, skill_id_labels, sentences):\n","\n","        with torch.no_grad():\n","\n","            # is_skill precision and recall\n","            tp = ((is_skill_logits > 0.0) & is_skill_labels).sum().item()\n","            fp = ((is_skill_logits > 0.0) & ~is_skill_labels).sum().item()\n","            fn = ((is_skill_logits <= 0.0) & is_skill_labels).sum().item()\n","            is_skill_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","            is_skill_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","\n","            # group entries by unique sentences\n","            sentence_to_indices = {}\n","            for i, sentence in enumerate(sentences.tolist()):\n","                sentence_to_indices.setdefault(sentence, []).append(i)\n","\n","            # init skill_id metrics\n","            mrr_sum, rp5_sum, atp_sum, count = 0, 0, 0, 0\n","\n","            # get probs and ranks\n","            probs = F.softmax(skill_id_logits / self.atp_temperature, dim=1)\n","            ranks = torch.argsort(skill_id_logits, dim=1, descending=True)\n","\n","            # process metrics per unique sentence\n","            for sentence, indices in sentence_to_indices.items():\n","\n","                # aggregate skill labels for the sentence, get softmax probs and sorted ranks\n","                sentence_labels = set(skill_id_labels[i].item() for i in indices if skill_id_labels[i] > -1)\n","\n","                # check for any labels\n","                if len(sentence_labels) == 0:\n","                    continue\n","\n","                # ATP calculation (average true probability)\n","                sentence_atp = probs[indices[0], list(sentence_labels)].sum().item()\n","                atp_sum += sentence_atp / len(sentence_labels)\n","\n","                # MRR calculation\n","                sentence_mrr = 0.0\n","                found_labels = set()\n","                for pos, pred in enumerate(ranks[indices[0]].tolist(), 1):\n","                    if pred in sentence_labels:\n","                        sentence_mrr += 1.0 / (pos - len(found_labels))\n","                        found_labels.add(pred)\n","                        if len(found_labels) == len(sentence_labels):\n","                            break\n","                mrr_sum += sentence_mrr / len(sentence_labels)\n","\n","                # RP@5 calculation\n","                top_k_correct = len(sentence_labels & set(ranks[indices[0], :5].tolist()))\n","                rp5_sum += top_k_correct / min(5, len(sentence_labels))\n","\n","                count += 1\n","\n","        # finalize metrics\n","        if count:\n","            skill_id_atp = atp_sum / count\n","            skill_id_rp5 = rp5_sum / count\n","            skill_id_mrr = mrr_sum / count\n","        else:\n","            skill_id_atp, skill_id_rp5, skill_id_mrr = None, None, None\n","\n","        return {\n","            'is_skill_pre': is_skill_precision,\n","            'is_skill_rec': is_skill_recall,\n","            'skill_id_atp': skill_id_atp,\n","            'skill_id_rp5': skill_id_rp5,\n","            'skill_id_mrr': skill_id_mrr\n","        }\n","\n","# init metrics\n","metrics = SkillMetrics(atp_temperature=C.ATP_TEMPERATURE).to(C.DEVICE)"],"metadata":{"id":"fU-OnTX73HlC","executionInfo":{"status":"ok","timestamp":1734524171210,"user_tz":-60,"elapsed":9,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_ydnFzovbmG-"},"source":["# Optimizer"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"k9K9SpX6awC9","executionInfo":{"status":"ok","timestamp":1734524171210,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}}},"outputs":[],"source":["# set n last layers trainable\n","for idx, layer in enumerate(base_model.encoder.layer):\n","    for param in layer.parameters():\n","        param.requires_grad = idx >= len(base_model.encoder.layer) - C.N_LAYERS\n","\n","# calculate layers to optimize learning for\n","n_layers = C.N_LAYERS - len(base_model.encoder.layer)\n","\n","# create param groups for optimizer with layer-wise learning rate  (factor applied per layer)\n","param_groups = reversed([\n","    {'params': base_model.encoder.layer[i].parameters(), 'lr': C.LR_INITIAL * C.LR_LAYER_FACTOR**-(i + 1)} for i in range(n_layers, 0)\n","])\n","\n","# adam with weight decay, default settings\n","optimizer = torch.optim.AdamW(param_groups, weight_decay=C.WEIGHT_DECAY_RATE)\n","\n","# mixed precision scaler\n","scaler = torch.amp.GradScaler(str(C.DEVICE))\n","\n","# collection of mixed precision backward pass calls\n","def backward(loss, optimizer, scaler):\n","    optimizer.zero_grad()\n","    scaler.scale(loss).backward()\n","    clip_grad_norm_(embedder.parameters(), max_norm=1.0)\n","    scaler.unscale_(optimizer)\n","    scaler.step(optimizer)\n","    scaler.update()"]},{"cell_type":"markdown","metadata":{"id":"4dDtnik0-opH"},"source":["# Logger"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"EfL7605b-nu6","executionInfo":{"status":"ok","timestamp":1734524171210,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}}},"outputs":[],"source":["# define module for logging\n","class Logger(nn.Module):\n","\n","    def __init__(self, optimizer, path):\n","        super().__init__()\n","        self.optimizer = optimizer\n","        self.path = path\n","\n","    def forward(self, epoch, data):\n","\n","        # init log data fields\n","        log_data = {'datetime': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","                    'epoch': epoch}\n","\n","        # gather log data\n","        log_data |= data\n","\n","        # init log with header\n","        if not os.path.exists(self.path):\n","            with open(self.path, 'w', newline='') as f:\n","                writer = csv.writer(f)\n","                writer.writerow(log_data.keys())\n","\n","        # log data for epoch\n","        with open(self.path, 'a', newline='') as f:\n","            writer = csv.writer(f)\n","            writer.writerow(log_data.values())\n","            f.flush()\n","\n","# initialize logging\n","logger = Logger(optimizer, path=C.PATH('.csv'))"]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"y_5iOXU-zz4w"}},{"cell_type":"code","source":["# decision variables\n","best_metric = float('inf') if (C.BEST_METRIC_OPT == 'min') else 0.0\n","patience_counter = 0\n","\n","# run through epochs\n","for epoch in range(C.EPOCHS):\n","\n","    # training mode\n","    embedder.train()\n","\n","    # init stats and progress bar\n","    train_stats = {}\n","    model_stats = {}\n","    pbar = tqdm(train_loader, desc=f'Training (epoch {epoch+1}/{C.EPOCHS})', unit='batch')\n","\n","    # train\n","    for num_batch, batch in enumerate(pbar):\n","        with torch.amp.autocast(str(C.DEVICE)):\n","\n","            # send batch to GPU\n","            batch = {k: v.to(C.DEVICE) for k, v in batch.items()}\n","\n","            # generate embeddings\n","            embeddings = embedder(batch['input_ids'], batch['attention_mask'])\n","\n","            # predictions\n","            is_skill_logits, skill_id_logits = predictor(embeddings, logits=True)\n","\n","            # truth\n","            is_skill_labels, skill_id_labels = batch['id'] > -1, batch['id']\n","\n","            # run batch\n","            loss, stats = criterion(is_skill_logits, is_skill_labels, skill_id_logits, skill_id_labels)\n","            stats |= metrics(is_skill_logits, is_skill_labels, skill_id_logits, skill_id_labels, batch['sentence'])\n","\n","        # backward pass\n","        backward(loss, optimizer, scaler)\n","\n","        # update progress\n","        train_stats = {\n","            k: [v] + train_stats.setdefault(k, [])\n","            for k, v in stats.items()\n","            if v is not None\n","        }\n","        model_stats = {\n","            'lr': [optimizer.param_groups[0]['lr']] + model_stats.setdefault('lr', []),\n","            'patience': [C.PATIENCE - patience_counter],\n","            'temperature': [criterion.skill_id_temperature] + model_stats.setdefault('temperature', []),\n","        }\n","\n","        pbar.set_postfix({k: sum(v) / len(v) for k, v in (model_stats | train_stats).items()})\n","\n","        # decay temperature\n","        criterion.skill_id_temperature = max(criterion.skill_id_temperature * C.SKILL_ID_TEMP_FACTOR, C.SKILL_ID_TEMP)\n","\n","        # warmup lr\n","        for param_group in optimizer.param_groups:\n","            if param_group['lr'] >= C.LR or patience_counter > 0:\n","                break\n","            param_group['lr'] = min(param_group['lr'] * C.LR_WARMUP_FACTOR, C.LR)\n","\n","    # update proxy embeddings after training / before validation\n","    predictor.update_embeddings()\n","\n","    # validation mode\n","    embedder.eval()\n","\n","    # init stats and progress bar\n","    val_stats = {}\n","    pbar = tqdm(val_loader, desc=f'Validation (epoch {epoch+1}/{C.EPOCHS})', unit='batch')\n","\n","    # results warehouse\n","    logits_and_labels = dict()\n","\n","    # validate\n","    with torch.no_grad():\n","        for num_batch, batch in enumerate(pbar):\n","\n","            # send batch to GPU\n","            batch = {k: v.to(C.DEVICE) for k, v in batch.items()}\n","\n","            # generate embeddings\n","            embeddings = embedder(batch['input_ids'], batch['attention_mask'])\n","\n","            # predictions\n","            is_skill_logits, skill_id_logits = predictor(embeddings, logits=True)\n","\n","            # truth\n","            is_skill_labels, skill_id_labels = batch['id'] > -1, batch['id']\n","\n","            # save logits and labels\n","            logits_and_labels.setdefault('is_skill_logits', []).append(is_skill_logits)\n","            logits_and_labels.setdefault('is_skill_labels', []).append(is_skill_labels)\n","            logits_and_labels.setdefault('skill_id_logits', []).append(skill_id_logits)\n","            logits_and_labels.setdefault('skill_id_labels', []).append(skill_id_labels)\n","            logits_and_labels.setdefault('sentence', []).append(batch['sentence'])\n","\n","        # run batch\n","        _, stats = criterion(*[torch.cat(v) for v in list(logits_and_labels.values())[:4]])\n","        stats |= metrics(*[torch.cat(v) for v in logits_and_labels.values()])\n","\n","        # update progress\n","        val_stats = {k: [v] + val_stats.setdefault(k, []) for k, v in stats.items() if v is not None}\n","        print('Validation:', ', '.join([f'{k} = {str(sum(v) / len(v))}' for k, v in val_stats.items()]))\n","\n","    # finalize stats\n","    train_stats = {k: sum(v) / len(v) for k, v in train_stats.items()}\n","    val_stats = {f'val_{k}': sum(v) / len(v) for k, v in val_stats.items()}\n","    model_stats = {k: sum(v) / len(v) for k, v in model_stats.items()}\n","\n","    # logging\n","    logger(epoch=epoch + 1, data=train_stats | val_stats | model_stats)\n","\n","    # save or break (if break, load best weights and restore embeddings)\n","    if not ((C.BEST_METRIC_OPT == 'min') - (val_stats[C.BEST_METRIC] < best_metric)):\n","        patience_counter = 0\n","        best_metric = val_stats[C.BEST_METRIC]\n","        torch.save({'embedder_state_dict': embedder.state_dict()}, C.PATH('.pth'))\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= C.PATIENCE:\n","            embedder.load_state_dict(torch.load(C.PATH('.pth'), weights_only=False)['embedder_state_dict'])\n","            predictor.update_embeddings()\n","            break\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] *= C.LR_REDUCE_FACTOR"],"metadata":{"id":"r_cpM1nHz1G5","executionInfo":{"status":"ok","timestamp":1734524171210,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"Q6_uQtvN7a4m"}},{"cell_type":"code","source":["# init stats and progress bar\n","test_stats = {}\n","pbar = tqdm(test_loader, desc=f'Test', unit='batch')\n","\n","# results warehouse\n","logits_and_labels = dict()\n","\n","# test\n","with torch.no_grad():\n","    for num_batch, batch in enumerate(pbar):\n","\n","        # test mode\n","        embedder.eval()\n","\n","        # send batch to GPU\n","        batch = {k: v.to(C.DEVICE) for k, v in batch.items()}\n","\n","        # generate embeddings\n","        embeddings = embedder(batch['input_ids'], batch['attention_mask'])\n","\n","        # predictions\n","        is_skill_logits, skill_id_logits = predictor(embeddings, logits=True)\n","\n","        # truth\n","        is_skill_labels, skill_id_labels = batch['id'] > -1, batch['id']\n","\n","        # save logits and labels\n","        logits_and_labels.setdefault('is_skill_logits', []).append(is_skill_logits)\n","        logits_and_labels.setdefault('is_skill_labels', []).append(is_skill_labels)\n","        logits_and_labels.setdefault('skill_id_logits', []).append(skill_id_logits)\n","        logits_and_labels.setdefault('skill_id_labels', []).append(skill_id_labels)\n","        logits_and_labels.setdefault('sentence', []).append(batch['sentence'])\n","        logits_and_labels.setdefault('group', []).append(batch['group'])\n","\n","    # concatenate\n","    logits_and_labels = {k: torch.cat(v) for k, v in logits_and_labels.items()}\n","\n","    # run batch\n","    _, stats = criterion(*list(logits_and_labels.values())[:4])\n","    stats |= metrics(*list(logits_and_labels.values())[:5])\n","\n","    # update progress\n","    test_stats = {k: [v] + test_stats.setdefault(k, []) for k, v in stats.items() if v is not None}\n","    print('Test:', ', '.join([f'{k} = {str(sum(v) / len(v))}' for k, v in test_stats.items()]))\n","\n","# finalize stats\n","test_stats = {k: sum(v) / len(v) for k, v in test_stats.items()}\n","\n","# logging\n","logger(epoch='test', data=test_stats)\n","\n","# group logging\n","for g in logits_and_labels['group'].unique():\n","    _, stats = criterion(*[v[g == logits_and_labels['group']] for v in list(logits_and_labels.values())[:4]])\n","    stats |= metrics(*[v[g == logits_and_labels['group']] for v in list(logits_and_labels.values())[:5]])\n","    logger(epoch=f'group{g}', data=stats)"],"metadata":{"id":"HG1_fRBXT0SK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734524197240,"user_tz":-60,"elapsed":26037,"user":{"displayName":"Jakob Mørup Wang","userId":"05964074732405401124"}},"outputId":"7ed541a3-cf37-45fb-adf1-9661ee87faaf"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Test: 100%|██████████| 227/227 [00:22<00:00, 10.12batch/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test: is_skill_loss = 0.13544845581054688, skill_id_loss = 9.176918983459473, is_skill_pre = 0.6150027578599007, is_skill_rec = 0.6148331954783568, skill_id_atp = 0.061303589541377636, skill_id_rp5 = 0.3473972602739728, skill_id_mrr = 0.26259662292801705\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1MlKDZyVcReI5nQkmE7e2RosHLiQbENRO","timestamp":1734255375067},{"file_id":"10LQunv9aj0FQgI5NQ53YR3YzxUQBB4Q3","timestamp":1734161138614},{"file_id":"1uJOGHr1Me4T9zV6nFCJ23lTXTkvutHh6","timestamp":1733730623039},{"file_id":"1iLJO3AQvHuXMFP0sawIZ6ZN5qBEmsC_I","timestamp":1724586680428},{"file_id":"18yIqsH9SZunvKNN1-uRRElJUbdr-1w_5","timestamp":1723621497459},{"file_id":"1sUMKHpx2Mu5y2w1T_4JEUU1MtYAY7c4I","timestamp":1723465352567}],"machine_shape":"hm","toc_visible":true,"gpuType":"A100","authorship_tag":"ABX9TyMSBTVU3n1UHWGeQ64AGfe9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"008d806633d849cfbbd1b6f54021794e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80ee07afcfcc4e659a0b9e7abef3bee0","IPY_MODEL_a398249b641e4c14b387c4777b2b4aa8","IPY_MODEL_9e562410dd7547f58eee8afac2cc9c9b"],"layout":"IPY_MODEL_6f1381ba18a14162aceeb927f69d7842"}},"80ee07afcfcc4e659a0b9e7abef3bee0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d19f08b590e45b38387acd902ec126c","placeholder":"​","style":"IPY_MODEL_478e703c6f2748f6bb472c649c75ed3c","value":"tokenizer_config.json: 100%"}},"a398249b641e4c14b387c4777b2b4aa8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34928e1edf7a47409386e932b3286898","max":402,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab919e8699dc4694bee0775b86a56422","value":402}},"9e562410dd7547f58eee8afac2cc9c9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb42de71b2cf4d1eb81cdb13bf9cf64e","placeholder":"​","style":"IPY_MODEL_c621449554fe486abb17f5ec21268d30","value":" 402/402 [00:00&lt;00:00, 32.7kB/s]"}},"6f1381ba18a14162aceeb927f69d7842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d19f08b590e45b38387acd902ec126c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"478e703c6f2748f6bb472c649c75ed3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34928e1edf7a47409386e932b3286898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab919e8699dc4694bee0775b86a56422":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cb42de71b2cf4d1eb81cdb13bf9cf64e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c621449554fe486abb17f5ec21268d30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1f135e9eddd41e297cb29efc050e339":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb2bd583958342f48ca700e07050edbb","IPY_MODEL_5fd145e907dd4441a661871c9db47c8b","IPY_MODEL_bf02100e17644d05a0c0d00753cfb1b1"],"layout":"IPY_MODEL_5e1bf183e85f41979d4829f451997bf3"}},"cb2bd583958342f48ca700e07050edbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c64533298c124910a4340704ba61df33","placeholder":"​","style":"IPY_MODEL_e430ce3ad0514ac6ac9b5dc497ae6f58","value":"config.json: 100%"}},"5fd145e907dd4441a661871c9db47c8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_287260ec7ee24aa19afd25eb999e110e","max":723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9975db8e08b3433faa0fd0cae982e5df","value":723}},"bf02100e17644d05a0c0d00753cfb1b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a81259cf21240638d99dbe73c3bc35d","placeholder":"​","style":"IPY_MODEL_55dac3e1755c438eade0ca392eb6387f","value":" 723/723 [00:00&lt;00:00, 61.0kB/s]"}},"5e1bf183e85f41979d4829f451997bf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c64533298c124910a4340704ba61df33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e430ce3ad0514ac6ac9b5dc497ae6f58":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"287260ec7ee24aa19afd25eb999e110e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9975db8e08b3433faa0fd0cae982e5df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a81259cf21240638d99dbe73c3bc35d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55dac3e1755c438eade0ca392eb6387f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21b3ca01d81c495392cebeb33326d347":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32e592dca9dd4852be3051d6dd09ba64","IPY_MODEL_1cd7a55470024a46a49d35b4864f5369","IPY_MODEL_5dfbecf2b3814ac08ea334b21526cf05"],"layout":"IPY_MODEL_3747ec1233ca4642899fb09bbdd6400c"}},"32e592dca9dd4852be3051d6dd09ba64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9757a8359ba4f6fb3650df806129b34","placeholder":"​","style":"IPY_MODEL_8e97b11d86c64da18fd6499c6c47cce6","value":"sentencepiece.bpe.model: 100%"}},"1cd7a55470024a46a49d35b4864f5369":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47cb0d14a1e04b81a06a460f59e35910","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cbc5b1f4a2048318101b02f2e0bd489","value":5069051}},"5dfbecf2b3814ac08ea334b21526cf05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87a80bd688814f2d97363192bd7def6e","placeholder":"​","style":"IPY_MODEL_c391cdc01b8e42f4aa97f1ee6e193c11","value":" 5.07M/5.07M [00:00&lt;00:00, 131MB/s]"}},"3747ec1233ca4642899fb09bbdd6400c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9757a8359ba4f6fb3650df806129b34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e97b11d86c64da18fd6499c6c47cce6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47cb0d14a1e04b81a06a460f59e35910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cbc5b1f4a2048318101b02f2e0bd489":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87a80bd688814f2d97363192bd7def6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c391cdc01b8e42f4aa97f1ee6e193c11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eef839ad3f6944f2a2ae1ba96e0eb060":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5226830a4d7e4fbe8d4c39e8ffdf5e57","IPY_MODEL_3a042f2bd84546b687812e0de5bca354","IPY_MODEL_d95a69a4d4944a9d944449bb9dd0b667"],"layout":"IPY_MODEL_cd3ebf24070b427da6cdaadbb851ad61"}},"5226830a4d7e4fbe8d4c39e8ffdf5e57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20071098e1e24e5a83d28bef2725d0c5","placeholder":"​","style":"IPY_MODEL_a862c53bd7264760ad4128766070f4cc","value":"tokenizer.json: 100%"}},"3a042f2bd84546b687812e0de5bca354":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb4d531a41a34fc69e168897bac1107a","max":9081518,"min":0,"orientation":"horizontal","style":"IPY_MODEL_908e5f5f11ff406a81e4641f5ccbd253","value":9081518}},"d95a69a4d4944a9d944449bb9dd0b667":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e971f36a0fb4b43862c0e00e84b7db8","placeholder":"​","style":"IPY_MODEL_f1b04dceb8a044e9a5fd7c9ea9055e35","value":" 9.08M/9.08M [00:08&lt;00:00, 1.03MB/s]"}},"cd3ebf24070b427da6cdaadbb851ad61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20071098e1e24e5a83d28bef2725d0c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a862c53bd7264760ad4128766070f4cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb4d531a41a34fc69e168897bac1107a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"908e5f5f11ff406a81e4641f5ccbd253":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e971f36a0fb4b43862c0e00e84b7db8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1b04dceb8a044e9a5fd7c9ea9055e35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c10ccc2c481045d4adb6a36e9e3b0c9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a81363afe1c741308b275a6a8609121b","IPY_MODEL_5c2044799e8943e6981ed72fae90505d","IPY_MODEL_1d41ecebb92442ba8a5362835dd5e22d"],"layout":"IPY_MODEL_5ecb00828e9445559f6702605534c70d"}},"a81363afe1c741308b275a6a8609121b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6d4e8e71e944a22b3cbfed1d96e5694","placeholder":"​","style":"IPY_MODEL_3061e0e9204a49c48188e1a444fe8755","value":"special_tokens_map.json: 100%"}},"5c2044799e8943e6981ed72fae90505d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3d8e556f0a944ddb6ccbd5665526d62","max":239,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3e028d402b6411fb04fc80ad82dba19","value":239}},"1d41ecebb92442ba8a5362835dd5e22d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52c7145abac04674b7394bc0ed6e1eae","placeholder":"​","style":"IPY_MODEL_8992cb7bd4ba4f43a05369a0b414f045","value":" 239/239 [00:00&lt;00:00, 21.1kB/s]"}},"5ecb00828e9445559f6702605534c70d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6d4e8e71e944a22b3cbfed1d96e5694":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3061e0e9204a49c48188e1a444fe8755":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3d8e556f0a944ddb6ccbd5665526d62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3e028d402b6411fb04fc80ad82dba19":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52c7145abac04674b7394bc0ed6e1eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8992cb7bd4ba4f43a05369a0b414f045":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcbcc1f8c4df4d8a9500b0d6fe1814e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_757008cb86264879922ac9c1690a022e","IPY_MODEL_9b6e6231f8684faa9312d63962888bf4","IPY_MODEL_feb29695d66f414684560afdf5bf1011"],"layout":"IPY_MODEL_d56edda780e24d97811fbf7de945d8c4"}},"757008cb86264879922ac9c1690a022e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40517a1596b243b3814cd2f072f4d70e","placeholder":"​","style":"IPY_MODEL_b85f08d974794e62a7c19a0208f92140","value":"model.safetensors: 100%"}},"9b6e6231f8684faa9312d63962888bf4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb499453ac174614a6f8daf1e83e548c","max":1112201288,"min":0,"orientation":"horizontal","style":"IPY_MODEL_917e84db6908496e84d21a40613a4338","value":1112201288}},"feb29695d66f414684560afdf5bf1011":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_507847201ec2413eb36d7f34aaaaae23","placeholder":"​","style":"IPY_MODEL_67403d7589984e9780938eacfb276f22","value":" 1.11G/1.11G [00:05&lt;00:00, 211MB/s]"}},"d56edda780e24d97811fbf7de945d8c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40517a1596b243b3814cd2f072f4d70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b85f08d974794e62a7c19a0208f92140":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb499453ac174614a6f8daf1e83e548c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"917e84db6908496e84d21a40613a4338":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"507847201ec2413eb36d7f34aaaaae23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67403d7589984e9780938eacfb276f22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}